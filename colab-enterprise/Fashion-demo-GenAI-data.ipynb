{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clfviNVNXpqj"
      },
      "source": [
        "## <img src=\"https://lh3.googleusercontent.com/mUTbNK32c_DTSNrhqETT5aQJYFKok2HB1G2nk2MZHvG5bSs0v_lmDm_ArW7rgd6SDGHXo0Ak2uFFU96X6Xd0GQ=w160-h128\" width=\"45\" valign=\"top\" alt=\"BigQuery\"> Fashion House Synthetic Data with Generative AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USHE_MDtfFed"
      },
      "source": [
        "### License"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7n8LMRIfFee"
      },
      "outputs": [],
      "source": [
        "##################################################################################\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "###################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDGexq5ZfFef"
      },
      "source": [
        "### Notebook Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B331LgblfFeg"
      },
      "source": [
        "\n",
        "Use LLMs for code generation.  You can start with a table schema with basic field descriptions\n",
        "\n",
        "1.   Create your table DDLs\n",
        "2.   Create LLM prompts for each table and ask it to populate the table with data\n",
        "3. Provide the prompts with starting primary keys\n",
        "4. Provide the prompts with foreign keys\n",
        "5. The LLM can understand that it decides the sizes and prices according to the item where applicable\n",
        "6. The LLM can read the description of each field and use that to generate valid values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DszuLZoo9A7k"
      },
      "source": [
        "### Initialize Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhKxJadjWa1R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import bigframes.pandas as bf\n",
        "#from bigframes.llm import BigFramesLLM\n",
        "from bigframes.ml.llm import PaLM2TextGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSC6-rboip3h"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "client = bigquery.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpU1P_fAXviJ"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"${project_id}\"\n",
        "REGION = \"us\"\n",
        "DATASET_ID = \"${dataset_id}\"\n",
        "CONNECTION_NAME = \"vertex-ai\"\n",
        "\n",
        "connection = f\"{PROJECT_ID}.{REGION}.{CONNECTION_NAME}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy7lRW09Ws1J"
      },
      "outputs": [],
      "source": [
        "session = bf.get_global_session()\n",
        "\n",
        "llm_model = PaLM2TextGenerator(session=session, connection_name=connection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YeExbVqf4ZE"
      },
      "source": [
        "### Supporting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtSLYNa_exfc"
      },
      "outputs": [],
      "source": [
        "def PrettyPrintJson(json_string):\n",
        "  json_object = json.loads(json_string)\n",
        "  json_formatted_str = json.dumps(json_object, indent=2)\n",
        "  print(json_formatted_str)\n",
        "  return json.dumps(json_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sthZI1h2fe8H"
      },
      "outputs": [],
      "source": [
        "def LLM(prompt, isOutputJson, max_output_tokens=1024, temperature=0, top_p=0, top_k=1):\n",
        "  print()\n",
        "  print(\"Prompt: \", prompt)\n",
        "  print()\n",
        "  df_prompt = pd.DataFrame(\n",
        "          {\n",
        "              \"prompt\": [prompt],\n",
        "          })\n",
        "  bf_df_prompt = bf.read_pandas(df_prompt)\n",
        "  prediction = llm_model.predict(bf_df_prompt,\n",
        "                                 max_output_tokens=max_output_tokens,\n",
        "                                 temperature=temperature, # 0 to 1 (1 random)\n",
        "                                 top_p=top_p, # 0 to 1 (1 random)\n",
        "                                 top_k=top_k, # (1 to 40 random)\n",
        "                                 ).to_pandas()\n",
        "  try:\n",
        "    # Remove common LLM output mistakes\n",
        "    result = prediction['ml_generate_text_llm_result'][0]\n",
        "\n",
        "    result = result.replace(\"```json\\n\",\"\")\n",
        "    result = result.replace(\"```JSON\\n\",\"\")\n",
        "    result = result.replace(\"```json\",\"\")\n",
        "    result = result.replace(\"```JSON\",\"\")\n",
        "    result = result.replace(\"```sql\\n\",\"\")\n",
        "    result = result.replace(\"```SQL\\n\",\"\")\n",
        "    result = result.replace(\"```sql\",\"\")\n",
        "    result = result.replace(\"```SQL\",\"\")\n",
        "    result = result.replace(\"```\",\"\")\n",
        "\n",
        "    if isOutputJson:\n",
        "      result = result.replace(\"\\n\",\" \")\n",
        "      json_string = PrettyPrintJson(result)\n",
        "      json_string = json_string.replace(\"'\",\"\\\\'\")\n",
        "      json_string = json_string.strip()\n",
        "      return json_string\n",
        "    else:\n",
        "      if \"INSERT INTO\" in result:\n",
        "        # do nothing (do not escape the single ticks, the LLM should do this\n",
        "        #             automatically for any text fields)\n",
        "        print(\"Do nothing\")\n",
        "      else:\n",
        "        result = result.replace(\"'\",\"\\\\'\")\n",
        "      result = result.strip()\n",
        "      return result\n",
        "\n",
        "  except:\n",
        "    print(\"Error (raw): \", prediction['ml_generate_text_llm_result'][0])\n",
        "    print(\"Error (result): \", result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8p8PkhFibYw"
      },
      "outputs": [],
      "source": [
        "def GetTableSchema(dataset_name, table_name):\n",
        "  import io\n",
        "\n",
        "  dataset_ref = client.dataset(dataset_name, project=PROJECT_ID)\n",
        "  table_ref = dataset_ref.table(table_name)\n",
        "  table = client.get_table(table_ref)\n",
        "\n",
        "  f = io.StringIO(\"\")\n",
        "  client.schema_to_json(table.schema, f)\n",
        "  return f.getvalue()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgMmeQSWvq6k"
      },
      "outputs": [],
      "source": [
        "def GetForeignKeys(dataset_name, table_name, field_name):\n",
        "  sql = f\"\"\"\n",
        "  SELECT STRING_AGG(CAST({field_name} AS STRING), \",\" ORDER BY {field_name}) AS result\n",
        "    FROM `{PROJECT_ID}.{dataset_name}.{table_name}`\n",
        "  \"\"\"\n",
        "  #print(sql)\n",
        "  df_result = client.query(sql).to_dataframe()\n",
        "  #display(df_result)\n",
        "  return df_result['result'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esIZXzKjsKIF"
      },
      "outputs": [],
      "source": [
        "def GetDistinctValues(dataset_name, table_name, field_name):\n",
        "  sql = f\"\"\"\n",
        "  SELECT STRING_AGG(DISTINCT {field_name}, \",\" ) AS result\n",
        "    FROM `{PROJECT_ID}.{dataset_name}.{table_name}`\n",
        "  \"\"\"\n",
        "  #print(sql)\n",
        "  df_result = client.query(sql).to_dataframe()\n",
        "  #display(df_result)\n",
        "  return df_result['result'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tto7sIdJ5vYi"
      },
      "outputs": [],
      "source": [
        "def GetStartingValue(dataset_name, table_name, field_name):\n",
        "  sql = f\"\"\"\n",
        "  SELECT IFNULL(MAX({field_name}),0) + 1 AS result\n",
        "    FROM `{PROJECT_ID}.{dataset_name}.{table_name}`\n",
        "  \"\"\"\n",
        "  #print(sql)\n",
        "  df_result = client.query(sql).to_dataframe()\n",
        "  #display(df_result)\n",
        "  return df_result['result'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sK-fbCaVMCZ"
      },
      "outputs": [],
      "source": [
        "def GetMaximumValue(dataset_name, table_name, field_name):\n",
        "  sql = f\"\"\"\n",
        "  SELECT IFNULL(MAX({field_name}),0) AS result\n",
        "    FROM `{PROJECT_ID}.{dataset_name}.{table_name}`\n",
        "  \"\"\"\n",
        "  #print(sql)\n",
        "  df_result = client.query(sql).to_dataframe()\n",
        "  #display(df_result)\n",
        "  return df_result['result'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFqXl0cefaOe"
      },
      "outputs": [],
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "\n",
        "  #return True # return early for now\n",
        "\n",
        "  job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "  query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "  # Check on the progress by getting the job's updated state.\n",
        "  query_job = client.get_job(\n",
        "      query_job.job_id, location=query_job.location\n",
        "  )\n",
        "  print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "  while query_job.state != \"DONE\":\n",
        "    time.sleep(2)\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "        )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "  if query_job.error_result == None:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUPdwNf_89Gq"
      },
      "source": [
        "### Create Tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ju475wfFej"
      },
      "source": [
        "- Here we are starting with our schema DDL and using our description to let the LLM know valid values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvfwRUU2YTXC"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.customer`\n",
        "(\n",
        "    customer_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    customer_name STRING NOT NULL OPTIONS(description=\"Name of the customer.\"),\n",
        "    customer_yob INT NOT NULL OPTIONS(description=\"Customer year of birth\"),\n",
        "    customer_email STRING NOT NULL OPTIONS(description=\"Customer's email address\"),\n",
        "    customer_inception_date DATE NOT NULL OPTIONS(description=\"Date of first customer interaction\")\n",
        "\n",
        ")\n",
        "CLUSTER BY customer_id;\n",
        "\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKK7KEnaH_Em"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "(\n",
        "    customer_review_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    customer_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Customer table\"),\n",
        "    review_datetime TIMESTAMP NOT NULL OPTIONS(description=\"Date and time of the review.\"),\n",
        "    review_text STRING NOT NULL OPTIONS(description=\"The customer's review of the product.\"),\n",
        "    review_audio STRING OPTIONS(description=\"The GCS location of an attached Audio file.\"),\n",
        "    review_sentiment STRING OPTIONS(description=\"The sentiment of the review text.\"),\n",
        "    social_media_source STRING NOT NULL OPTIONS(description=\"The social media site the review was posted on.\"),\n",
        "    social_media_handle STRING NOT NULL OPTIONS(description=\"The customer's social media handle\"),\n",
        "    gen_ai_recommended_action STRING OPTIONS(description=\"Valid values for gen_ai_recommended_action are: 'Send Survey', 'Send Coupon'\"),\n",
        "    gen_ai_reponse STRING OPTIONS(description=\"The Generated response from the LLM.\"),\n",
        "    human_response STRING OPTIONS(description=\"The human manually entered response.\"),\n",
        "    response_sent_action STRING OPTIONS(description=\"Valid values for response_sent_action are: 'Sent LLM Response', 'Human called'\"),\n",
        "    response_sent_date TIMESTAMP OPTIONS(description=\"Date and time the response was sent.\")\n",
        "\n",
        ")\n",
        "CLUSTER BY customer_id;\n",
        "\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bktx53fDfszf"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"ALTER TABLE `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "  ADD COLUMN IF NOT EXISTS llm_detected_theme JSON OPTIONS(description=\"The LLM detected themes in the customer review.\");\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mIv7Q-DRxI4"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.product`\n",
        "(\n",
        "    product_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    product_name STRING NOT NULL OPTIONS(description=\"The name of the product apparel or accessory\"),\n",
        "    product_price FLOAT64 NOT NULL OPTIONS(description=\"The price of the product\"),\n",
        "    product_description STRING NOT NULL OPTIONS(description=\"The detailed description of the product\"),\n",
        "    item_size STRING NOT NULL OPTIONS(description=\"Valid Values: Small, Medium, Large\")\n",
        "\n",
        ")\n",
        "CLUSTER BY product_id;\n",
        "\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uiu6p13mAjQG"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.order`\n",
        "(\n",
        "    order_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    customer_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Customer table.\"),\n",
        "    order_datetime TIMESTAMP NOT NULL OPTIONS(description=\"The datetime the order was started.\"),\n",
        "    order_completion_datetime TIMESTAMP NOT NULL OPTIONS(description=\"The datetime the order was completed.\")\n",
        "\n",
        ")\n",
        "CLUSTER BY order_id;\n",
        "\"\"\"\n",
        "\n",
        "client.query(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoR5uQmLEOiJ"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.order_item`\n",
        "(\n",
        "    order_item_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    order_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Order table\"),\n",
        "    product_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Product table\"),\n",
        "    quantity INTEGER NOT NULL OPTIONS(description=\"Number of items ordered\")\n",
        "\n",
        ")\n",
        "CLUSTER BY order_id;\n",
        "\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}.historical_sales`\n",
        "(\n",
        "    order_item_id INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    order_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Order table\"),\n",
        "    product_id INTEGER NOT NULL OPTIONS(description=\"Foreign key: Product table\"),\n",
        "    quantity INTEGER NOT NULL OPTIONS(description=\"Number of items ordered\"),\n",
        "    price FLOAT64 NOT NULL OPTIONS(description=\"Price of the product\"),\n",
        "    order_datetime TIMESTAMP NOT NULL OPTIONS(description=\"The datetime the order was completed.\"),\n",
        "    total_sales_amount FLOAT64 NOT NULL OPTIONS(description=\"Total sales amount for this order, multipling quantity by price.\")\n",
        ")\n",
        "CLUSTER BY order_id;\n",
        "\"\"\"\n",
        "\n",
        "RunQuery(sql)\n"
      ],
      "metadata": {
        "id": "SordZsSbdL88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlhRKtPAsAWz"
      },
      "source": [
        "### Customer Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk0dNDwba44U"
      },
      "outputs": [],
      "source": [
        "sql = f\"\"\"ALTER TABLE `{PROJECT_ID}.{DATASET_ID}.customer`\n",
        "  ADD COLUMN IF NOT EXISTS country_code STRING OPTIONS(description=\"The home country of the customer.\");\"\"\"\n",
        "\n",
        "RunQuery(sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwWRZChiFTIl"
      },
      "outputs": [],
      "source": [
        "customer_count = 10\n",
        "country = \"Sweden\"\n",
        "country_code = \"SE\"\n",
        "\n",
        "table_name = \"customer\"\n",
        "primary_key = \"customer_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DcfseTbsB8u"
      },
      "outputs": [],
      "source": [
        "loop_count = 1\n",
        "loop_index = 1\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a database engineer and need to generate data for a table for the below schema.\n",
        "  - The schema is for a Google Cloud BigQuery Table.\n",
        "  - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "  - Read the description of each field for valid values.\n",
        "  - Do not preface the response with any special characters or 'sql'.\n",
        "  - Generate {customer_count} insert statements for this table.\n",
        "  - The customer_inception_date is a date and should be within the past 2 years.\n",
        "  - The customer_name should be names used in the country {country} and be a first and last name.\n",
        "  - The starting value of the field {primary_key} is {starting_value}.\n",
        "  - Only generate a single statement, not multiple INSERTs.\n",
        "  - Set the country_code to {country_code}\n",
        "\n",
        "  Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "  Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "  Schema: {schema}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbxE7eDp-L1j"
      },
      "source": [
        "### Customer Review Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg8ZZEViq9lu"
      },
      "source": [
        "### Create customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VwUtOMh-L1j"
      },
      "outputs": [],
      "source": [
        "rows_of_data_to_generate = 3\n",
        "\n",
        "table_name = \"customer\"\n",
        "field_name = \"customer_id\"\n",
        "customer_ids = GetForeignKeys(DATASET_ID, table_name, field_name)\n",
        "\n",
        "table_name = \"customer_review\"\n",
        "primary_key = \"customer_review_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVm36Q_1-L1k"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "loop_count = 10\n",
        "loop_index = 1\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  if random.random() < .25:\n",
        "    prompt=f\"\"\"\n",
        "    You are a database engineer and need to generate data for a table for the below schema.\n",
        "    You need to generate reviews for customers who have purchased your clothing or accessories.\n",
        "    Write a negative in first person based upon the following: \"Bad Quality\",\"Long Delivery Time\",\"Dirty\",\"Overpriced\",\"Not great options\",\"Clothes not according to weather\",\"Lack of options\",\"Inconsistent Quality\",\"Lack of knowledgable staff\",\"No Matching accessories\",\"Not true to size\",\"Limited Options\",\"Delayed Delivery\",\"Return not straight forward\"\n",
        "    - The schema is for a Google Cloud BigQuery Table.\n",
        "    - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "    - Read the description of each field for valid values.\n",
        "    - Do not preface the response with any special characters or 'sql'.\n",
        "    - Generate {rows_of_data_to_generate} insert statements for this table.\n",
        "    - Valid values for customer_id are: {customer_ids}\n",
        "    - The review_datetime is a date and should be within the past year.\n",
        "    - The response for each question should be 20 to 100 words.\n",
        "    - The starting value of the field {primary_key} is {starting_value}.\n",
        "    - Only generate a single statement, not multiple INSERTs.\n",
        "    - Escape single quotes with a backslash.  Example: Kim's Answer: Kim\\'s\n",
        "    - Only generate data for these fields: customer_review_id, customer_id, review_datetime, review_text, social_media_source, social_media_handle\n",
        "\n",
        "    Examples:\n",
        "    Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "    Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "    Schema: {schema}\n",
        "    \"\"\"\n",
        "  else:\n",
        "    prompt=f\"\"\"\n",
        "    You are a database engineer and need to generate data for a table for the below schema.\n",
        "    You need to generate reviews for customers who have purchased your clothing or accessories.\n",
        "    Write a positive or neutral review in first person based upon the following: \"Good Quality\",\"Short Delivery Time\",\"Clean\",\"Good value\",\"Great Options\",\"Clothes according to weather\",\"Great matching accessory options\",\"Consistent Quality\",\"True to size\",\"Timely delivery\",\"Easy return options\",\"Good Selection\"\n",
        "    - The schema is for a Google Cloud BigQuery Table.\n",
        "    - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "    - Read the description of each field for valid values.\n",
        "    - Do not preface the response with any special characters or 'sql'.\n",
        "    - Generate {rows_of_data_to_generate} insert statements for this table.\n",
        "    - Valid values for customer_id are: {customer_ids}\n",
        "    - The review_datetime is a date and should be within the past year.\n",
        "    - The response for each question should be 20 to 100 words.\n",
        "    - The starting value of the field {primary_key} is {starting_value}.\n",
        "    - Only generate a single statement, not multiple INSERTs.\n",
        "    - Escape single quotes with a backslash.  Example: Kim's Answer: Kim\\'s\n",
        "    - Only generate data for these fields: customer_review_id, customer_id, review_datetime, review_text, social_media_source, social_media_handle\n",
        "\n",
        "    Examples:\n",
        "    Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "    Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "    Schema: {schema}\n",
        "    \"\"\"\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWUogwtAqNTT"
      },
      "source": [
        "### Score the Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSB45vFQPnaM"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"SELECT customer_review_id,\n",
        "                review_text\n",
        "          FROM `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "         WHERE review_sentiment IS NULL\n",
        "        ORDER BY customer_review_id\n",
        "\"\"\"\n",
        "\n",
        "# Fields to update\n",
        "# review_sentiment,\n",
        "# gen_ai_recommended_action,\n",
        "# gen_ai_reponse,\n",
        "# human_response,\n",
        "# response_sent_action,\n",
        "# response_sent_date\n",
        "\n",
        "df_process = client.query(sql).to_dataframe()\n",
        "\n",
        "for row in df_process.itertuples():\n",
        "  customer_review_id = row.customer_review_id\n",
        "  review_text = row.review_text\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      prompt=f\"\"\"\n",
        "      For the given review classify the sentiment as Positive, Neutral or Negative.\n",
        "      Review: {review_text}\n",
        "      \"\"\"\n",
        "      review_sentiment = LLM(prompt, False, max_output_tokens=10, temperature=0, top_p=0, top_k=1)\n",
        "\n",
        "      sql = f\"\"\"UPDATE `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "                  SET review_sentiment = '{review_sentiment}'\n",
        "                WHERE customer_review_id = {customer_review_id}\n",
        "      \"\"\"\n",
        "\n",
        "      print (sql)\n",
        "\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      llm_valid_execution = True\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W_Dr1xGqRML"
      },
      "source": [
        "### Gen AI Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJeGxIYwqUlc"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"SELECT customer_review_id,\n",
        "                review_text\n",
        "          FROM `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "         WHERE gen_ai_reponse IS NULL\n",
        "        ORDER BY customer_review_id\"\"\"\n",
        "\n",
        "df_process = client.query(sql).to_dataframe()\n",
        "\n",
        "for row in df_process.itertuples():\n",
        "  customer_review_id = row.customer_review_id\n",
        "  review_text = row.review_text\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      prompt=f\"\"\"\n",
        "      Generate responses to the below customer review who purchased clothing or accessories and return the results the below json format.\n",
        "      The review can be positive, negative, or neutral.\n",
        "      Provide a variety of responses, including thanking customers for positive reviews, addressing concerns in negative reviews, and engaging with neutral reviews.\n",
        "      Please generate at least 5 different responses.\n",
        "\n",
        "      JSON format: [ \"value\" ]\n",
        "      Sample JSON Response: [ \"response 1\", \"response 2\", \"response 3\", \"response 4\", \"response 5\" ]\n",
        "\n",
        "      Review: {review_text}\"\"\"\n",
        "\n",
        "      json_result = LLM(prompt, True, max_output_tokens=1024, temperature=0, top_p=0, top_k=1)\n",
        "      print(f\"json_result: {json_result}\")\n",
        "\n",
        "      if json_result == None:\n",
        "        llm_valid_execution = False\n",
        "      else:\n",
        "        sql = f\"\"\"UPDATE `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "                    SET gen_ai_reponse = '{json_result}'\n",
        "                  WHERE customer_review_id = {customer_review_id}\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"sql: {sql}\")\n",
        "\n",
        "        llm_valid_execution = RunQuery(sql)\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azULzoGAqVGz"
      },
      "source": [
        "### Gen AI Recommended Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noL3Es8tqjr0"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"SELECT customer_review_id,\n",
        "                review_text\n",
        "          FROM `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "         WHERE gen_ai_recommended_action IS NULL\n",
        "        ORDER BY customer_review_id\"\"\"\n",
        "\n",
        "df_process = client.query(sql).to_dataframe()\n",
        "\n",
        "for row in df_process.itertuples():\n",
        "  customer_review_id = row.customer_review_id\n",
        "  review_text = row.review_text\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      prompt=\"\"\"\n",
        "      Select one of the following actions based upon the below customer review who purchased clothing or accessories.\n",
        "      - First randomly sort the actions.\n",
        "      - Select the best action based upon the sentiment of the review.\n",
        "      - It is okay to use the action \"Send the customer a coupon\" for both positive and negative reviews.\n",
        "      - Return the results the below json format.\n",
        "      - Do not include any special characters or \"```json\" in the json output\n",
        "\n",
        "      Actions\n",
        "      - \"Thank the Customer\"\n",
        "      - \"Apologize to the Customer\"\n",
        "      - \"Send the customer a coupon\"\n",
        "      - \"Call the customer\"\n",
        "      - \"Promote Additional Products\"\n",
        "      - \"Promise to Investigate\"\n",
        "      - \"Encourage More Reviews\"\n",
        "      - \"Invite Further Engagement\"\n",
        "      - \"Reshare the review on other social media\"\n",
        "\n",
        "      JSON format: { \"action\" : \"value\", \"explaination\" : \"llm explaination\" }\n",
        "      Sample JSON Response: { \"action\" : \"Call the customer\", \"explaination\" : \"The customer left their phone number in the review.\" }\n",
        "      Sample JSON Response: { \"action\" : \"Encourage More Reviews\", \"explaination\" : \"Thanks for the review, please keep posting.\" }\n",
        "\n",
        "      Review:\"\"\"\n",
        "      prompt = prompt + review_text\n",
        "\n",
        "      json_result = LLM(prompt, True, max_output_tokens=1024, temperature=0, top_p=0, top_k=1)\n",
        "      print(f\"json_result: {json_result}\")\n",
        "\n",
        "      if json_result == None:\n",
        "        llm_valid_execution = False\n",
        "      else:\n",
        "        sql = f\"\"\"UPDATE `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "                    SET gen_ai_recommended_action = '{json_result}'\n",
        "                  WHERE customer_review_id = {customer_review_id}\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"sql: {sql}\")\n",
        "\n",
        "        llm_valid_execution = RunQuery(sql)\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOtL7RgiZox9"
      },
      "source": [
        "### Detect Customer Themes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7r3Kzovd-y2"
      },
      "outputs": [],
      "source": [
        "sql = \"\"\"SELECT customer_review_id,\n",
        "                review_text\n",
        "          FROM `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "         WHERE llm_detected_theme IS NULL\n",
        "        ORDER BY customer_review_id\"\"\"\n",
        "\n",
        "df_process = client.query(sql).to_dataframe()\n",
        "\n",
        "for row in df_process.itertuples():\n",
        "  customer_review_id = row.customer_review_id\n",
        "  review_text = row.review_text\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      prompt=\"\"\"\n",
        "      Classify the below customer review as one or more of the below themes.\n",
        "      - Return the results the below json format.\n",
        "      - Include an explaination for selecting each theme.\n",
        "      - Do not include double quotes in the explaination.\n",
        "      - Do not include any special characters, double quotes or \"```json\" in the json output.\n",
        "\n",
        "      Themes\n",
        "      - \"Bad Service\"\n",
        "      - \"Long Delivery Time\"\n",
        "      - \"Slow Service\"\n",
        "      - \"Dirty\"\n",
        "      - \"Overpriced\"\n",
        "      - \"Overcrowded\"\n",
        "      - \"Noisy Location\"\n",
        "      - \"Lack of options available\"\n",
        "      - \"Inconsistent Quality\"\n",
        "      - \"Not true to size\"\n",
        "      - \"No Variety of accessories\"\n",
        "      - \"Too few options\"\n",
        "      - \"Options not according to weather\"\n",
        "      - \"Good Service\"\n",
        "      - \"Short Delivery Time\"\n",
        "      - \"Knowledgeable Staff\"\n",
        "      - \"Clean\"\n",
        "      - \"Good value\"\n",
        "      - \"Value for moeny\"\n",
        "      - \"Quite Location\"\n",
        "      - \"Variety of Alternatives\"\n",
        "      - \"Consistent Quality\"\n",
        "      - \"Lots of matching accessories\"\n",
        "      - \"Lots of weather appropriate options\"\n",
        "      - \"Easy returns\"\n",
        "      - \"Good Online Selection\"\n",
        "\n",
        "      JSON format: [{ \"theme\" : \"value\", \"explaination\" : \"llm explaination\" }]\n",
        "      Sample JSON Response: [{ \"theme\" : \"Fast Service\", \"explaination\" : \"The customer got their order fast.\" }]\n",
        "      Sample JSON Response: [{ \"theme\" : \"Overpriced\", \"explaination\" : \"The customer said it was too expensive.\" }]\n",
        "\n",
        "      Review:\"\"\"\n",
        "      prompt = prompt + review_text\n",
        "\n",
        "      json_result = LLM(prompt, True, max_output_tokens=1024, temperature=0, top_p=0, top_k=1)\n",
        "      print(f\"json_result: {json_result}\")\n",
        "\n",
        "      if json_result == None:\n",
        "        llm_valid_execution = False\n",
        "      else:\n",
        "        sql = f\"\"\"UPDATE `{PROJECT_ID}.{DATASET_ID}.customer_review`\n",
        "                    SET llm_detected_theme = JSON'{json_result}'\n",
        "                  WHERE customer_review_id = {customer_review_id}\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"sql: {sql}\")\n",
        "\n",
        "        llm_valid_execution = RunQuery(sql)\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuv45clVnqUf"
      },
      "source": [
        "### Product Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wyRzw-QFHm-"
      },
      "outputs": [],
      "source": [
        "table_name = \"product\"\n",
        "primary_key = \"product_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlEe3aBvf33F"
      },
      "outputs": [],
      "source": [
        "loop_count = 1\n",
        "loop_index = 1\n",
        "product_count = 20\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "\n",
        "  # Get Product Names\n",
        "  product_count = 20\n",
        "\n",
        "  table_name = \"product\"\n",
        "  field_name = \"product_name\"\n",
        "  existing_values = GetDistinctValues(DATASET_ID, table_name, field_name)\n",
        "\n",
        "  prompt = f\"\"\"Generate {product_count} different clothing and accessory names for spring weather and return in the below json format.\n",
        "  - The name can be an existing clothing or something new.\n",
        "  - The name can be an existing accessory or something new.\n",
        "  - The name should be related to fashion in Nordics with Spring weather as theme.\n",
        "  - Do not use any of these names: [{existing_values}]\n",
        "  - Do not number the results.\n",
        "\n",
        "  JSON format: [ \"value\" ]\n",
        "  Sample JSON Response: [ \"value1\", \"value2\" ]\n",
        "  \"\"\"\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      product_name = LLM(prompt, True, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      llm_valid_execution = True\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)\n",
        "\n",
        "\n",
        "  # Insert data\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a database engineer and need to generate data for a table for the below schema.\n",
        "  - The schema is for a Google Cloud BigQuery Table.\n",
        "  - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "  - Read the description of each field for valid values.\n",
        "  - Do not preface the response with any special characters or 'sql'.\n",
        "  - Valid values for item_name are: {product_name}\n",
        "  - The starting value of the field {primary_key} is {starting_value}.\n",
        "  - Only generate a single statement, not multiple INSERTs.\n",
        "\n",
        "  Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "  Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "  Schema: {schema}\n",
        "  \"\"\"\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeDoqMQNAFcE"
      },
      "source": [
        "### Order Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8Aoyg2hE_Ru"
      },
      "outputs": [],
      "source": [
        "order_count = 10\n",
        "\n",
        "table_name = \"customer\"\n",
        "field_name = \"customer_id\"\n",
        "max_customer_id = GetMaximumValue(DATASET_ID, table_name, field_name)\n",
        "\n",
        "table_name = \"order\"\n",
        "primary_key = \"order_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPmtl23VAFcO"
      },
      "outputs": [],
      "source": [
        "loop_count = 50\n",
        "loop_index = 1\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a database engineer and need to generate data for a table for the below schema.\n",
        "  - The schema is for a Google Cloud BigQuery Table.\n",
        "  - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "  - Read the description of each field for valid values.\n",
        "  - Do not preface the response with any special characters or 'sql'.\n",
        "  - Generate {order_count} insert statements for this table.\n",
        "  - The order_datetime is a date and should be within the past 1 year.\n",
        "  - The order_completion_datetime should be within 60 to 900 seconds of the order_datetime.\n",
        "  - Valid values for customer_id between 1 and {max_customer_id}.\n",
        "  - The starting value of the field {primary_key} is {starting_value}.\n",
        "  - Only generate a single statement, not multiple INSERTs.\n",
        "  - Timestamps should use this format: 2020-06-02 23:57:12.120174 UTC.\n",
        "\n",
        "  Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "  Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "  Schema: {schema}\n",
        "  \"\"\"\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      sql = sql.replace(\"\\\\'\",\"'\")\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bni86QYEusy"
      },
      "source": [
        "### Order Item Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op7cuZl0F60U"
      },
      "outputs": [],
      "source": [
        "order_item_count = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1EdHmZrFbc9"
      },
      "outputs": [],
      "source": [
        "table_name = \"product\"\n",
        "field_name = \"product_id\"\n",
        "max_product_id = GetMaximumValue(DATASET_ID, table_name, field_name)\n",
        "\n",
        "table_name = \"order\"\n",
        "field_name = \"order_id\"\n",
        "max_order_id = GetMaximumValue(DATASET_ID, table_name, field_name)\n",
        "\n",
        "table_name = \"order_item\"\n",
        "primary_key = \"order_item_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KYEq_cjEusy"
      },
      "outputs": [],
      "source": [
        "loop_count = 100\n",
        "loop_index = 1\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  max_order_item_id = GetMaximumValue(DATASET_ID, table_name, \"order_id\")\n",
        "\n",
        "  if max_order_item_id > max_order_id:\n",
        "    print(\"Breaking out of loop since we have items for each order.\")\n",
        "    break\n",
        "\n",
        "  order_id_to_generate_data = max_order_item_id + 1\n",
        "  print(f\"order_id_to_generate_data: {order_id_to_generate_data}\")\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a database engineer and need to generate data for a table for the below schema.\n",
        "  - The schema is for a Google Cloud BigQuery Table.\n",
        "  - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "  - Read the description of each field for valid values.\n",
        "  - Do not preface the response with any special characters or 'sql'.\n",
        "  - Generate {order_item_count} insert statements for this table.\n",
        "  - You can have 1 to 10 items for a single order_id.\n",
        "  - The order_id should use the value of: {order_id_to_generate_data}.\n",
        "  - Valid values for quantity as between 1 and 4.\n",
        "  - The starting value of the field {primary_key} is {starting_value}.\n",
        "  - Only generate a single statement, not multiple INSERTs.\n",
        "\n",
        "  Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "  Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "  Schema: {schema}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Historical Sales Table"
      ],
      "metadata": {
        "id": "TJzfKHzEfUaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_item_count = 3"
      ],
      "metadata": {
        "id": "K3MJYxP5g7qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_name = \"trending_product\"\n",
        "field_name = \"product_id\"\n",
        "##Add restriction from trending product for product id in prompt\n",
        "\n",
        "table_name = \"order\"\n",
        "field_name = \"order_id\"\n",
        "max_order_id = GetMaximumValue(DATASET_ID, table_name, field_name)\n",
        "\n",
        "table_name = \"historical_sales\"\n",
        "primary_key = \"order_item_id\"\n",
        "\n",
        "schema = GetTableSchema(DATASET_ID, table_name)"
      ],
      "metadata": {
        "id": "TyVkgIdEff3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loop_count = 100\n",
        "loop_index = 1\n",
        "\n",
        "while loop_index <= loop_count:\n",
        "  print(f\"loop_index: {loop_index} | loop_count: {loop_count}\")\n",
        "  starting_value = GetStartingValue(DATASET_ID, table_name, primary_key)\n",
        "\n",
        "  max_order_item_id = GetMaximumValue(DATASET_ID, table_name, \"order_id\")\n",
        "\n",
        "  if max_order_item_id > max_order_id:\n",
        "    print(\"Breaking out of loop since we have items for each order.\")\n",
        "    break\n",
        "\n",
        "  order_id_to_generate_data = max_order_item_id + 1\n",
        "  print(f\"order_id_to_generate_data: {order_id_to_generate_data}\")\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "  You are a database engineer and need to generate data for a table for the below schema.\n",
        "  - The schema is for a Google Cloud BigQuery Table.\n",
        "  - The table name is \"{PROJECT_ID}.{DATASET_ID}.{table_name}\".\n",
        "  - This table is to have historical sales data for last year to be used for BigQuery ARIMA PLUS forecasting model.\n",
        "  - Read the description of each field for valid values.\n",
        "  - Do not preface the response with any special characters or 'sql'.\n",
        "  - Generate {order_item_count} insert statements for this table.\n",
        "  - You can have 1 to 10 items for a single order_id.\n",
        "  - The order_id should use the value of: {order_id_to_generate_data}.\n",
        "  - Valid values for product_id 1 and 2. Do not include more values.\n",
        "  - The order_datetime is a date and should be between 2023-04-01 and 2024-04-15, generate order for each day.\n",
        "  - Valid values for quantity as between 1 and 100.\n",
        "  - The starting value of the field {primary_key} is {starting_value}.\n",
        "  - Only generate a single statement, not multiple INSERTs.\n",
        "\n",
        "  Example 1: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Sample'),(2, 'Sample');\n",
        "  Example 2: INSERT INTO `my-dataset.my-dataset.my-table` (field_1, field_2) VALUES (1, 'Data'),(2, 'Data'),(3, 'Data');\n",
        "\n",
        "  Schema: {schema}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  llm_valid_execution = False\n",
        "  while llm_valid_execution == False:\n",
        "    try:\n",
        "      sql = LLM(prompt, False, max_output_tokens=1024, temperature=1, top_p=1, top_k=40)\n",
        "      print(\"---------------------------------\")\n",
        "      print(\"sql: \", sql)\n",
        "      print(\"---------------------------------\")\n",
        "      llm_valid_execution = RunQuery(sql)\n",
        "      loop_index = loop_index + 1\n",
        "    except Exception as error:\n",
        "      print(\"An error occurred:\", error)"
      ],
      "metadata": {
        "id": "OjX1VGWygtdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80fLTGc8BOji"
      },
      "source": [
        "### Learnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re1SPznGBRwB"
      },
      "source": [
        "Issues:\n",
        "- LLMs take time for each call\n",
        "- This is a demo to create small dataset\n",
        "- Output contains: ```\n",
        "- Output contains: ```sql\n",
        "- dates are not always valid dates \"2017-09-31\" to type DATE\n",
        "- for UUIDs, use an INT and then swap to UUID later (add a column and then do an update)\n",
        "- LLM returns single quotes in strings.  Had to prompt or string.replace.\n",
        "- Probally need to use Min/Max of primary key for ints.\n",
        "- Sometimes the LLM generates multiple insert..intos\n",
        "- Inserts are sometimes many INSERTS and not many values\n",
        "\n",
        "Learnings\n",
        "- The LLM can generate Small, Medium and Large (for applicable products) with pricing that is correct.\n",
        "- The LLM can understand the schema\n",
        "- The LLM can understand the description (valid values)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DszuLZoo9A7k",
        "6YeExbVqf4ZE",
        "CUPdwNf_89Gq",
        "Jr2sIqNP800E",
        "deSLhzKC8qHQ",
        "nlhRKtPAsAWz",
        "ylfzCAIzEALT",
        "WbxE7eDp-L1j",
        "Mg8ZZEViq9lu",
        "Wuv45clVnqUf",
        "KeDoqMQNAFcE",
        "0Bni86QYEusy",
        "QRmg26z6fZ3F",
        "xpGwpvfcfZ3P",
        "eHSGhbkZfZ3R",
        "CqrzJy8ofn_V",
        "CZkWyPdPf191",
        "oIGyz0ZmfT-p",
        "80fLTGc8BOji"
      ],
      "name": "Fashion-demo-GenAI-data.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}